Let $\probabilitySpace$ be a probability space where $\outcomes$ is a set of outcomes, $\sigmaAlgebra$ is a $\sigma$-algebra on $\outcomes$, and $\probabilityMeasure: \sigmaAlgebra \to [0, 1]$ is a probability measure \cite{durrett2010}. A random variable (\rv) is defined as a $\sigmaAlgebra$-measurable function $X: \outcomes \to \real$. An $n$-dimensional \rv\ is then a vector of $n$ \rvs. In what follows, the probability space $\probabilitySpace$ is always implied.

Consider a heterogeneous multiprocessor system that consists of $\ncores$ processing elements and is equipped with a thermal package. The processing elements are the active components of the system identified at the intended level of granularity (processors, ALUs, caches, registers, \etc). Let $\specification$ be a thermal specification of the system defined as a collection of temperature-related information. Specifically, $\specification$ contains (a) the floorplans of the active layers of the chip; (b) the geometry of the thermal package; (c) the thermal parameters of the materials that the chip and package are made of. In addition, the system depends on a set of uncertain parameters, denoted by a random element $\U$, which manifest themselves in deviations of the actual power dissipation from nominal values and, consequently, in deviations of temperature from the one corresponding to the nominal power consumption.

A power profile $\profileP$ is a tuple composed of a data matrix $\mP = (\P_{ij}) \in \real^{\ncores \times \npsteps}$ that captures the power dissipation of all the $\ncores$ processing elements at $\npsteps$ moments of time and a (column) vector $\partition{\mP} = (\t_i) \in \real^{\npsteps}$ with positive and strictly increasing components that specifies these moments of time. The definition of a temperature profile $\profileT$ is the same as the one for power except that the data matrix $\mT = (\T_{ij}) \in \real^{\ncores \times \nsteps}$ contains temperature.

The goal of this work is to develop an UQ framework for characterization of the uncertain parametrization $\U$ impacting a multiprocessor platform by analyzing the corresponding temperature profiles collected at a few instantiations of the platform, \eg, at several dies on the wafer. Denote by
\[
  \data = \left( \profilePdyn, \; \; \{ (\mT^{(i)}_\meas, \partition{\mT}) \}_{i = 1}^\ndata, \; \; \{ \r_i \}_{i = 1}^\ndata \right)
\]
a data set composed of (a) a dynamic power profile $\profilePdyn$; (b) $\ndata$ temperature measurements $(\mT^{(i)}_\meas, \partition{\mT})$, corresponding to $\profilePdyn$, of $\ndata$ dies on the wafer; (c) the spatial locations  $\r_i$ of the dies. The test power profile is assumed to be fine-grained whereas temperature profiles are presumably sparse; for simplicity, the latter are also assumed to have the same time partition $\partition{\mT}$. The input to the framework should be composed of (a) a thermal specification $\specification$ of the platform; (b) a data set $\data$ as defined above; and, optionally, (c) a prior knowledge on the distribution of $\U$. Taking into account both the prior knowledge and observed data, the framework should deliver an estimate of the probability distribution of the uncertain parameters with the desired level of accuracy and at low computational costs.
