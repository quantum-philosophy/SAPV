Process variation constitutes one of the major concerns of electric system designs \cite{srivastava2010}. A crucial implication of process variation is that it renders the key parameters of a technological process, \eg, the effective channel length, gate oxide thickness, and threshold voltage, as uncertain quantities.
Therefore, a purely deterministic workload applied to two ``identical'' dies can lead to two different power and, thus, temperature profiles since they essentially depend on those stochastic quantities. Consequently, process variation leads to performance degradation in the best case and to burnt silicon in the worst.
Under these circumstances, uncertainty quantification (UQ) has evolved into an indispensable asset of the electric system fabrication workflows that can provide high guaranties on the efficiency and robustness of their products to the end users.

An important target of UQ is the characterization of the on-wafer distribution of a quantity of interest (QoI), deteriorated by process variation, based on a data set of measurements. The problem belongs to the class of inverse UQ problems as the QoI is an input and the measurements are an output; this is opposed to direct problems wherein one studies outputs based on the knowledge of inputs (see, \eg, \cite{juan2011, juan2012}).
Such an inverse problem is addressed in this paper: our goal is to quantify distributions of the key process parameters, \eg\ the effective channel length, and we approach this goal by measuring temperature and analyzing it using Bayesian inference \cite{gelman2004}.

Bayesian inference is utilized in \cite{zhang2010} to identify an optimal set of spatial locations on the wafer, in which the QoI, such as the effective channel length, should be measured in order to characterize it with the maximal accuracy.
In \cite{paek2012}, the authors consider an inverse problem focused on the inference of the power dissipation based on transient temperature profiles using Markov random fields.
Another temperature-based characterization of power is developed in \cite{mesa-martinez2007} wherein a genetic algorithm is employed for reconstruction of the power model.
It should be noted that the approach in \cite{zhang2010} requires test structures to be deployed onto each die on the wafer as it operates on direct observations of the QoI. This can be expensive and, thus, impractical to undertake. The techniques in \cite{paek2012} and \cite{mesa-martinez2007} solely focus on power and do not attempt to dive deeper and quantify the primary sources of uncertainty.

Our work makes the following main contributions. First, we propose a novel approach to the quantification of process variations based on indirect, incomplete, and noisy measurements. Indirectness is the key ingredient as it allows for a significant decrease of the costs associated with the process variation identification. Second, we develop a solid framework around the proposed idea in order to make the method readily available for practical instantiations. Third, we present a thorough study of various aspects of the framework that are of high practical interest.

The remainder of this paper is organized as follows. A motivational example is given in \sref{motivation}. In \sref{problem-formulation}, we formulate the addressed problem and state our solution. The proposed framework is developed in \sref{proposed-framework}. The experimental results are reported in \sref{experimental-results}. \sref{conclusion} concludes the paper. The work also contains a set of supplementary materials given in the appendix.
