Let us turn to the sampling stage, Stage~3 in \fref{algorithm}. As noted earlier, we utilize the Metropolis-Hastings algorithm for sampling. In order to speed up this process, we would like to make use of the omnipresent multicore parallelization for sampling. To this end, instead of utilizing the classical proposal mentioned in \sref{optimization}---which is purely sequential as the mean for the next sample draw is dependent on the previous sample---we appeal to a variation of the Metropolis-Hastings algorithm called the independence sampler \cite{gelman2004}. In this case, a typical choice of the proposal is a multivariate t-distribution, independent of the current position of the chain:
\begin{equation} \elabel{proposal}
  \vparam \sim \studentst{\nu}{\hat{\vparam}}{\alpha^2 \mOI^{-1}}
\end{equation}
where $\hat{\vparam}$ and $\mOI$ are as in \sref{optimization}, $\nu$ is the number of degrees of freedom, and $\alpha$ is a tuning constant. Now the proposal draws and the time-consuming evaluation of their posterior in \eref{log-posterior} can be computed for all samples in parallel.
Then the precomputed draws and their posterior evaluations can subsequently be accepted or rejected as in the usual Metropolis-Hasting algorithm.

Having completed the sampling procedure, we obtain a collection of samples of $\vparam$. Due to the burn-in period (see \sref{bayesian-inference}), a certain number of initial samples are typically discarded as being unrepresentative.
Each of the preserved samples of $\vparam$ is then used in \eref{kl-approximation} to compute a sample of $\u$, $\u_i \in \real^{\ndies \nprocs}$.
Denote such a data set with $\nsamples$ samples of the \qoi\ by $\UData = \{ \u_i \}_{i = 1}^\nsamples$.
