Let $\vparam$ be a set of parameters that are uncertain for us either in nature or due to our limited knowledge. The goal is to characterize the distribution of $\vparam$ given a data set of observations $\Data$ and some prior believes on $\vparam$. A natural solution is to rely on Bayes' rule \cite{gelman2004}:
\begin{equation} \elabel{bayes}
  \text{\small Posterior} = \frac{\text{\small Likelihood} \times \text{\small Prior}}{\text{\small Evidence}}, \; \f{\vparam | \Data} = \frac{\f{\Data | \vparam} \f{\vparam}}{\f{\Data}},
\end{equation}
where $\f{\cdot}$ denotes a probability density function, and the vertical bars stand for conditioning. $\f{\vparam}$ is called the prior of $\vparam$, $\f{\vparam | \Data}$ is the corresponding posterior, $\f{\Data | \vparam}$ is the likelihood function, and $\f{\Data}$ is a normalization constant. Challenging problems often do not have closed-form expressions for posterior distributions. For instance, when modeling a physical process, the likelihood function may involve solving a system of differential equations; it is the case for our problem (see \sref{thermal-model}). Thus, in order to be able to draw samples from the posterior, one usually relies on Monte Carlo (MC) sampling and, in particular, on Markov Chain Monte Carlo (MCMC) sampling \cite{gelman2004}, which we also do.
