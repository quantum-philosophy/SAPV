In this subsection, we discuss three aspects of our framework that help to speed up the inference procedure.

\subsubsection{Approximation of the Forward Model} \slabel{analytical-solution}
First, we address the complexity of $\model$. The model is expensive as it involves a system of nonlinear differential equations (see \eref{heat-de}), which should be solved numerically using, \eg, Runge-Kutta methods \cite{press2007}. In order to mitigate these repetitive computations, we utilize the approach discussed in detail in \cite{ukhov2012}.
The idea is that, if the power term on the right-hand side of \eref{heat-de} stays constant, the system becomes linear and obtains an analytical solution. When the simulated time interval was short enough, the technique was found to have a negligibly small influence on the resulting accuracy; however, the speedup was found to be considerable.
Since $\profilePdyn$ is fine-grained, we can assume that the total power changes only at the time moments $\t_i \in \partition{\mP}$ (see \sref{problem-formulation}). In this way, we can stride in time solving \eref{heat-de} for each step analytically and, thus, gaining a significant speedup. See \cite{ukhov2012} for further details.

\subsubsection{Tailored Proposal Distribution} \slabel{proposal-distribution}
As discussed in \sref{bayesian-inference}, the core of the Metropolis algorithm is the proposal distribution. A carefully constructed proposal can significantly reduce the number of steps needed for the corresponding Markov chain to start producing representative samples; in other words, it can save a lot of forward model evaluations, which are computationally intensive.
A common technique to construct a high-quality proposal is to undertake an optimization procedure of the log-posterior function given by \eref{log-posterior}, which we also do. Specifically, we seek for such a value of $\vparam$ that maximizes \eref{log-posterior}.
Consequently, the optimization yields a highly probable value of $\vparam$, denoted by $\hat{\vparam}$, along with the corresponding Hessian matrix, denoted by $\mOI$. The two form a solid base for the proposal distribution.
For example, a classical choice of such a distribution is a multivariate Gaussian distribution wherein the mean is the current location of the Markov chain started from $\hat{\vparam}$, and the covariance matrix is the inverse of $\mOI$. Refer to \cite{gelman2004} for further details.

\subsubsection{Sampling Strategy} \slabel{sampling-strategy}
We make use of the omnipresent multicore parallelization for sampling. To this end, instead of utilizing the classical proposal mentioned in \sref{proposal-distribution}---which is purely sequential as the mean for the next sample draw depends on the previous sample---we appeal to the independence sampler Metropolis algorithm \cite{gelman2004}. In this case, a typical choice of the proposal is a multivariate t-distribution, which is independent of the current position of the chain:
\begin{equation} \elabel{proposal}
  \vparam \sim \studentst{\nu}{\hat{\vparam}}{\alpha^2 \mOI^{-1}}
\end{equation}
where $\hat{\vparam}$ and $\mOI$ are as in \sref{proposal-distribution}, $\nu$ is the number of degrees of freedom, and $\alpha$ is a tuning constant. Now, the posterior in \eref{log-posterior} can be computed for all samples in parallel.
