Let $\vparam$ be a set of parameters that are uncertain for us. The goal is to characterize $\vparam$ given (a) a data set of observations $\Data$, (b) a forward model for $\Data$ parametrized by $\vparam$, and (c) prior beliefs on $\vparam$. A natural solution is to rely on Bayes' rule \cite{gelman2004}:
\[
  \text{\small Posterior} = \frac{\text{\small Likelihood} \times \text{\small Prior}}{\text{\small Evidence}}, \; \f{\vparam | \Data} = \frac{\f{\Data | \vparam} \f{\vparam}}{\f{\Data}},
\]
where $\f{\cdot}$ denotes a probability density function, and the vertical bars stand for conditioning \cite{durrett2010}. $\f{\vparam}$ is called the prior of $\vparam$, $\f{\vparam | \Data}$ is the corresponding posterior, $\f{\Data | \vparam}$ is the likelihood function, and $\f{\Data}$ is a normalization constant.
Due to the forward model involved in the likelihood function, the posterior is often not available in closed form.
For instance, a physical phenomenon, such as heat transfer, may introduce a system of differential equations in $\f{\Data | \vparam}$, which is the case in our problem (see \sref{thermal-model}).
To tackle the difficulty, one usually has to rely on such techniques as Markov Chain Monte Carlo (MCMC) sampling \cite{gelman2004}, which simulates an ergodic Markov chain in the parameter space with the stationary distribution equal to the target posterior distribution.
A popular instantiation of MCMC sampling is the Metropolis-Hastings algorithm where, at iteration $t$, a draw $\vparam_t$ is simulated from a proposal distribution $q(\vparam_t | \vparam_{t - 1})$. The proposed draw is then accepted in the posterior samples with probability
\[
  \probabilityMeasure(\text{accept } \vparam_t) = \min\left(1, \frac{\f{\vparam_t |  \Data} q(\vparam_t | \vparam_{t - 1})}{\f{\vparam_{t - 1} | \Data} q(\vparam_{t - 1} | \vparam_t)} \right).
\]
If the draw is rejected, $\vparam_t := \vparam_{t - 1}$.
