Process variation constitutes one of the major concerns of electric system designs \cite{chandrakasan2001, srivastava2010}. A crucial implication of process variation is that it renders the key parameters of a technological process, \eg, the effective channel length, gate oxide thickness, and threshold voltage, as uncertain quantities.
Therefore, the same workload applied to two ``identical'' dies can lead to two different power and, thus, temperature profiles since they essentially depend on those stochastic quantities.
Consequently, process variation leads to performance degradation in the best case and to burnt silicon in the worst scenario.
Under these circumstances, uncertainty quantification has evolved into an indispensable asset of the fabrication workflows that can provide high guaranties on the efficiency and robustness of their products.

An important target of uncertainty quantification is the characterization of the on-wafer distribution of a quantity of interest (\qoi), deteriorated by process variation, based on a data set of measurements.
The problem belongs to the class of so-called inverse problems since the \qoi\ can be seen as an input and the measurements as an output, which is opposed to direct problems wherein one studies outputs based on the knowledge of inputs (see, \eg, \cite{juan2011, juan2012}).
Such an inverse problem is addressed in this paper: our goal is to quantify distributions of the key process parameters, \eg, the effective channel length, and we approach this goal by measuring temperature and analyzing it via the machinery of Bayesian inference \cite{gelman2004}.

Bayesian inference is utilized in \cite{zhang2010} to identify an optimal set of locations on the wafer, in which the \qois\ should be measured in order to characterize them with the maximal accuracy.
In \cite{paek2012}, the authors consider an inverse problem focused on the inference of the power dissipation based on transient temperature profiles using Markov random fields.
Another temperature-based characterization of power is developed in \cite{mesa-martinez2007} wherein a genetic algorithm is employed for reconstruction of the power model.
It should be noted that the approach in \cite{zhang2010} requires test structures to be deployed onto each die on the wafer as it operates on direct measurements, which can be expensive and, thus, impractical to undertake. Moreover, the technique in \cite{zhang2010}, focusing on frequencies, voltages, and currents, is not capable of characterizing the primary sources of uncertainty such as the effective channel length and gate oxide thickness since it would require the measured dies to be destroyed. The approaches in \cite{paek2012} and \cite{mesa-martinez2007}, on the other hand, solving the inverse temperature-to-power problem, are not aware of process variation.

Our work makes the following main contributions. First, we propose a novel approach to the quantification of process variation based on a data set of indirect, incomplete, and noisy measurements. Indirectness is the key ingredient as it allows for a significant decrease of the costs associated with the process variation characterization. Second, we develop a solid framework around the proposed idea in order to make the method readily available for practical implementations. Third, we present a thorough study of various aspects of the framework that are of high practical interests.

The remainder of the paper is organized as follows. A motivational example is given in \sref{motivation}. In \sref{problem-formulation}, we formulate the problem, which we address, and state our solution. Preliminary materials on Bayesian inference are given in \sref{preliminaries}. The proposed framework is presented in \sref{proposed-framework}, which is followed by the experimental results reported in \sref{experimental-results}. \sref{conclusion} concludes the paper. The work also includes a set of supplementary materials given in the appendix.
