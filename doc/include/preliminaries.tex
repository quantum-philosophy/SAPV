In order to give a clear presentation of the proposed technique, we first overview the basics of Bayesian inference \cite{gelman2004}.
Let $\vparam$ be a set of unknown parameters (in our case, related to, \eg, the effective channel length), which we would like to characterize.
Our arsenal to solve the problem includes: (a) a set of observations $\QData$ (in our case, \eg, temperature or current); (b) a data model connecting $\vparam$ with $\QData$; and (c) prior beliefs on $\vparam$.
A natural solution is Bayes' rule:
\begin{equation} \elabel{bayes}
  \f{\vparam | \QData} \propto \f{\QData | \vparam} \; \f{\vparam}
\end{equation}
where $\f{\cdot}$ denotes a probability density function.
$\f{\QData | \vparam}$ is known as the likelihood function, which accommodates the data model and yields the probability of observing the data $\QData$ given the parameters $\vparam$.
$\f{\vparam}$ is called the prior of $\vparam$, which represents our knowledge on $\vparam$ prior to any observations.
$\f{\vparam | \QData}$ reads as the posterior of $\vparam$ given $\QData$.
Such a posterior is an exhaustive solution to our problem: having constructed $\f{\vparam | \QData}$, all the needed characteristics of $\vparam$ can be trivially estimated by drawing samples from this posterior.

Unfortunately, the posterior distribution often does not belong to any of the common families of probability distributions, which is primarily due to the data model involved in the likelihood function, and, therefore, the sampling procedure is not straightforward.
To tackle the difficulty, one usually relies on such techniques as Markov Chain Monte Carlo (MCMC) sampling \cite{gelman2004}. In this case, an ergodic Markov chain with the stationary distribution equal to the target posterior distribution is constructed and then utilized for the probability space exploration.
A popular instantiation of MCMC sampling is the Metropolis-Hastings (MH) algorithm wherein such a Markov chain is attained via sampling from an auxiliary, computationally convenient distribution known as the proposal distribution. We shall further elaborate on this algorithm in \sref{statistical-model}--\sref{sampling}.
