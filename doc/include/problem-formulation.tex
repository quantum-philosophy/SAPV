Let $\pspace$ be a probability space where $\outcomes$ is a set of outcomes, $\salgebra$ is a $\sigma$-algebra on $\outcomes$, and $\pmeasure: \salgebra \to [0, 1]$ is a probability measure \cite{durrett2010}. A random variable (\rv) is defined as a $\salgebra$-measurable function $X: \outcomes \to \real$. An $n$-dimensional \rv\ is then a vector of $n$ \rvs. In what follows, the probability space $\pspace$ is always implied.

Consider a heterogeneous multiprocessor system that consists of $\ncores$ processing elements and is equipped with a thermal package. The processing elements are the active components of the system identified at the intended level of granularity (processors, ALUs, caches, registers, \etc). Let $\specification$ be a thermal specification of the system defined as a collection of temperature-related information. Specifically, $\specification$ contains (a) the floorplans of the active layers of the chip; (b) the geometry of the thermal package; (c) the thermal parameters of the materials that the chip and package are made of. In addition, the system depends on a set of uncertain parameters, denoted by a random vector $\vU$, which manifest themselves in deviations of the actual power dissipation from nominal values and, consequently, in deviations of temperature from the one corresponding to the nominal power consumption.

A power profile $\profileP$ is a tuple composed of a data matrix $\mP = \left(\vP_1, \dotsc, \vP_{\nsteps} \right) \in \real^{\ncores \times \nsteps}$ that captures the power dissipation of all the $\ncores$ processing elements at $\nsteps$ moments of time and a vector with strictly increasing components $\partition{\mP} = (\t_1, \dotsc, \t_{\nsteps})^T$ that specifies these moments of time. The definition of a temperature profile $\profileT$ is the same as the one for power except that the data matrix $\mT = \left( \vT_1, \dots, \vT_{\nsteps} \right) \in \real^{\ncores \times \nsteps}$ contains temperature. We denote a measurement-based data set of $\ndata$ temperature profiles by $\data = \{ (\mT^{(i)}_\meas, \partition{\mT}) \}_{i = 1}^{\ndata}$ where, for simplicity but without loss of generality, the time partitions are assumed to be equivalent.

The goal of this work is to develop an UQ framework for characterization of the uncertain parameters $\vU$ impacting a multiprocessor platform by analyzing temperature samples collected at different instantiations of the platform, \eg, at different dies on a wafer. The input to the framework should be composed of (a) a thermal specification $\specification$ of the platform; (b) a data set of temperature measurements $\data$; (c) the dynamic power profile $\profilePdyn$, which was used to obtain $\data$; and, optionally, (d) a prior knowledge on the distribution of the uncertain parameters $\vU$. The test power profile is assumed to be fine-grained whereas temperature profiles are presumably sparse. Taking into account both the prior knowledge and observed data, the framework should deliver an estimate of the probability distribution of the uncertain parameters with the desired level of accuracy and at low computational costs.
